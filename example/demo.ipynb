{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLarge.llm import LLMAugmenter\n",
    "\n",
    "llm_aug = LLMAugmenter()\n",
    "res = llm_aug.paraphrase_with_question(\"This movie is a must-watch for all the family.\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLarge.random import RandomAugmenter\n",
    "from NLarge.random import Action\n",
    "\n",
    "random_aug = RandomAugmenter()\n",
    "random_aug(\"This is a simple example sentence for testing.\", action=Action.SWAP, target_words=[\"awesome\", \"great\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NLarge.synonym import SynonymAugmenter\n",
    "\n",
    "syn_aug = SynonymAugmenter()\n",
    "\n",
    "sample_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "syn_aug(sample_text, aug_src='wordnet', aug_p=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import Dataset, Features, Value, concatenate_datasets\n",
    "from NLarge.dataset_concat import augment_data, MODE\n",
    "from NLarge.pipeline import TextClassificationPipeline\n",
    "from NLarge.model.RNN import TextClassifierRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train_data, original_test_data = datasets.load_dataset(\n",
    "    \"rotten_tomatoes\", split=[\"train\", \"test\"]\n",
    ")\n",
    "\n",
    "features = Features({\"text\": Value(\"string\"), \"label\": Value(\"int64\")})\n",
    "original_train_data = Dataset.from_dict(\n",
    "    {\n",
    "        \"text\": original_train_data[\"text\"],\n",
    "        \"label\": original_train_data[\"label\"],\n",
    "    },\n",
    "    features=features,\n",
    ")\n",
    "\n",
    "original_train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment and increase size by 100%\n",
    "percentages = {\n",
    "    MODE.RANDOM.SUBSTITUTE: 0.5,  # 50% of data for random augmentation\n",
    "    MODE.SYNONYM.WORDNET: 0.5,  # 50% of data for synonym augmentation\n",
    "}\n",
    "\n",
    "augmented_data_list = augment_data(original_train_data, percentages)\n",
    "\n",
    "\n",
    "# Convert augmented data into Datasets\n",
    "augmented_dataset = Dataset.from_dict(\n",
    "    {\n",
    "        \"text\": [item[\"text\"] for item in augmented_data_list],\n",
    "        \"label\": [item[\"label\"] for item in augmented_data_list],\n",
    "    },\n",
    "    features=features,\n",
    ")\n",
    "\n",
    "# Concatenate original and augmented datasets\n",
    "augmented_train_data = concatenate_datasets(\n",
    "    [original_train_data, augmented_dataset]\n",
    ")\n",
    "\n",
    "print(f\"Original train size: {len(original_train_data)}\")\n",
    "print(f\"Train size after 100% augmentation: {len(augmented_train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_augmented = TextClassificationPipeline(\n",
    "    augmented_data=augmented_train_data,\n",
    "    test_data=original_test_data,\n",
    "    max_length=128,\n",
    "    test_size=0.2,\n",
    "    model_class=TextClassifierRNN,\n",
    ")\n",
    "pipeline_augmented.train_model(n_epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
